# -*- coding: utf-8 -*-
"""Testing_features.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PbrcaVHHLqiIIMM9H01sdr9gZAFMZLII

### Set Up
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt  
import seaborn as seabornInstance 
from sklearn.model_selection import train_test_split 
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures
from sklearn.metrics import mean_squared_error, r2_score
from sklearn import metrics 
from sklearn import datasets
from sklearn.multiclass import OneVsRestClassifier
from sklearn.svm import LinearSVC
from sklearn.datasets import fetch_mldata
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn import tree
from sklearn.neural_network import MLPClassifier
from sklearn.preprocessing import label_binarize
from sklearn.neural_network import MLPRegressor
from sklearn.metrics import roc_auc_score
import seaborn as sn
import os

from google.colab import files
uploaded = files.upload()

df1 = pd.read_csv('./steam_raw.csv')
df2 = pd.read_csv('./Tags_2.csv')

df1.head()

df2.head()

"""### Data Cleaning"""

# remove unwanted columns
to_drop = ['appid', 'name', 'english', 'developer', 'publisher', 'platforms', 'genres']
df1.drop(to_drop, inplace=True, axis=1)

to_drop = ['appid','360_video','feature_film']
df2.drop(to_drop, inplace=True, axis=1)

# remove zeros in columns
df1['price'] = df1['price'].astype(float)
df1['required_age'] = df1['required_age'].astype(float)
df1['achievements'] = df1['achievements'].astype(float)
df1['average_playtime'] = df1['average_playtime'].astype(float)
df1 = df1[df1.price != 0]
df1.describe()

df2.describe()

# combine ratings
df1.insert(1, 'total_ratings', ' ', True)
df1.total_ratings = df1.positive_ratings+df1.negative_ratings;

df1.insert(4, 'ratings', ' ', True) 
df1['ratings'] = df1['positive_ratings']/(df1['positive_ratings'] + df1['negative_ratings'])

# remove unwanted ratings columns
to_drop = ['positive_ratings', 'negative_ratings']
df1.drop(to_drop, inplace=True, axis=1)
df1.head()

# extract the year
df1['release_year'] = pd.DatetimeIndex(df1['release_date']).year

# remove release_date column
to_drop = ['release_date']
df1.drop(to_drop, inplace=True, axis=1)

# split owners
df1[['min_owners','max_owners']] = df1['owners'].str.split('-',expand=True)

# calculate average yearly revenue
df1.insert(8, 'avg_revenue', ' ', True) 
df1['min_owners'] = df1['min_owners'].astype(float)
df1['max_owners'] = df1['max_owners'].astype(float)
df1['price'] = df1['price'].astype(float)
df1['release_year'] = df1['release_year'].astype(float)
df1['avg_revenue'] = (df1['min_owners'] + df1['max_owners'])/2 * df1['price'] / (2020 - df1['release_year'])

# remove columns
to_drop = ['release_year', 'min_owners', 'max_owners', 'owners']
df1.drop(to_drop, inplace=True, axis=1)

# insert column for multi-player and single-player
df1.insert(1, 'singleplayer', ' ', True) 
df1.insert(2, 'multiplayer', ' ', True)

# make categories lowercase
df1['categories'] = df1['categories'].str.lower()
df1['steamspy_tags'] = df1['steamspy_tags'].str.lower()

# Populate columns with True/False
df1['singleplayer'] = df1['categories'].str.contains('single-player')
df1['multiplayer'] = df1['categories'].str.contains('multi-player')

# Change to binary 0/1
df1['singleplayer'] = df1['singleplayer'].astype(int)
df1['multiplayer'] = df1['multiplayer'].astype(int)

to_drop = ['categories', 'steamspy_tags']
df1.drop(to_drop, inplace=True, axis=1)

# mean normalization + feature scaling
achievements_std = df1['achievements'].std()
achievements_mean = df1.achievements.mean()
df1.achievements = (df1.achievements - achievements_mean)/achievements_std

price_std = df1['price'].std()
price_mean = df1.price.mean()
df1.price = (df1.price - price_mean)/price_std

avg_playtime_std = df1['average_playtime'].std()
avg_playtime_mean = df1.average_playtime.mean()
df1.average_playtime = (df1.average_playtime - avg_playtime_mean)/avg_playtime_std

med_playtime_std = df1['median_playtime'].std()
med_playtime_mean = df1.median_playtime.mean()
df1.median_playtime = (df1.median_playtime - med_playtime_mean)/med_playtime_std

total_ratings_std = df1.total_ratings.std()
total_ratings_mean = df1.total_ratings.mean()
df1.total_ratings = (df1.total_ratings - total_ratings_mean)/total_ratings_std

required_age_std = df1.required_age.std()
required_age_mean = df1.required_age.mean()
df1.required_age = (df1.required_age - required_age_mean)/required_age_std

df2 = (df2 - df2.mean())/df2.std()

df2.head()

df1.describe()

# dropping average_playtime and median_playtime
to_drop = ['average_playtime', 'median_playtime']
df1.drop(to_drop, inplace=True, axis=1)
df1.head()

df1.shape

df2.shape

# Combine the two dataframes
df = df1.reset_index().merge(df2.reset_index(), left_index=True, right_index=True, how='left')

# remove index_x and index_y column
to_drop = ['index_x','index_y','singleplayer_y','multiplayer_y']
df.drop(to_drop, inplace=True, axis=1)

df.shape

df.head()

"""### Binning data"""

# Run this if rerunning binning
#to_drop = ['bin']
#df.drop(to_drop, inplace=True, axis=1)

# Split into bins
df.insert(375, 'bins', ' ', True) 
bin_num = np.linspace(start=0,stop=3,num=4)
#df.bins = pd.qcut(df.avg_revenue, q=4, labels=bin_num)

bins_revenue = [0, 20000, 80000, 500000, 700000000]
df.bins = pd.cut(df.avg_revenue, bins=bins_revenue, labels=bin_num)
df['bins'] = df['bins'].astype(int)
df.head()

df.describe()

# To check if there is any null values 

df.isnull().sum().sum()

"""### Split data into training and test"""

# Stratified sampling
X = df[['ratings', 'total_ratings', 'achievements', 'price', 'required_age', 'singleplayer_x', 	'multiplayer_x',	'1980s', 	'1990s', 	'2.5d', 	'2d', 	'2d_fighter', 	'3d', 	'3d_platformer', 	'3d_vision', 	'4_player_local', 	'4x', 	'6dof', 	'atv', 	'abstract', 	'action', 	'action_rpg', 	'action_adventure', 	'addictive', 	'adventure', 	'agriculture', 	'aliens', 	'alternate_history', 	'america', 	'animation_&_modeling', 	'anime', 	'arcade', 	'arena_shooter', 	'artificial_intelligence', 	'assassin', 	'asynchronous_multiplayer', 	'atmospheric', 	'audio_production', 	'bmx', 	'base_building', 	'baseball', 	'based_on_a_novel', 	'basketball', 	'batman', 	'battle_royale', 	'beat_em_up', 	'beautiful', 	'benchmark', 	'bikes', 	'blood', 	'board_game', 	'bowling', 	'building', 	'bullet_hell', 	'bullet_time', 	'crpg', 	'capitalism', 	'card_game', 	'cartoon', 	'cartoony', 	'casual', 	'cats', 	'character_action_game', 	'character_customization', 	'chess', 	'choices_matter', 	'choose_your_own_adventure', 	'cinematic', 	'city_builder', 	'class_based', 	'classic', 	'clicker', 	'co_op', 	'co_op_campaign', 	'cold_war', 	'colorful', 	'comedy', 	'comic_book', 	'competitive', 	'conspiracy', 	'controller', 	'conversation', 	'crafting', 	'crime', 	'crowdfunded', 	'cult_classic', 	'cute', 	'cyberpunk', 	'cycling', 	'dark', 	'dark_comedy', 	'dark_fantasy', 	'dark_humor', 	'dating_sim', 	'demons', 	'design_&_illustration', 	'destruction', 	'detective', 	'difficult', 	'dinosaurs', 	'diplomacy', 	'documentary', 	'dog', 	'dragons', 	'drama', 	'driving', 	'dungeon_crawler', 	'dungeons_&_dragons', 	'dynamic_narration', 	'dystopian_', 	'early_access', 	'economy', 	'education', 	'emotional', 	'epic', 	'episodic', 	'experience', 	'experimental', 	'exploration', 	'fmv', 	'fps', 	'faith', 	'family_friendly', 	'fantasy', 	'fast_paced', 	'female_protagonist', 	'fighting', 	'first_person', 	'fishing', 	'flight', 	'football', 	'foreign', 	'free_to_play', 	'funny', 	'futuristic', 	'gambling', 	'game_development', 	'gamemaker', 	'games_workshop', 	'gaming', 	'god_game', 	'golf', 	'gore', 	'gothic', 	'grand_strategy', 	'great_soundtrack', 	'grid_based_movement', 	'gun_customization', 	'hack_and_slash', 	'hacking', 	'hand_drawn', 	'hardware', 	'heist', 	'hex_grid', 	'hidden_object', 	'historical', 	'hockey', 	'horror', 	'horses', 	'hunting', 	'illuminati', 	'indie', 	'intentionally_awkward_controls', 	'interactive_fiction', 	'inventory_management', 	'investigation', 	'isometric', 	'jrpg', 	'jet', 	'kickstarter', 	'lego', 	'lara_croft', 	'lemmings', 	'level_editor', 	'linear', 	'local_co_op', 	'local_multiplayer', 	'logic', 	'loot', 	'lore_rich', 	'lovecraftian', 	'mmorpg', 	'moba', 	'magic', 	'management', 	'mars', 	'martial_arts', 	'massively_multiplayer', 	'masterpiece', 	'match_3', 	'mature', 	'mechs', 	'medieval', 	'memes', 	'metroidvania', 	'military', 	'mini_golf', 	'minigames', 	'minimalist', 	'mining', 	'mod', 	'moddable', 	'modern', 	'motocross', 	'motorbike', 	'mouse_only', 	'movie', 	'multiple_endings', 	'music', 	'music_based_procedural_generation', 	'mystery', 	'mystery_dungeon', 	'mythology', 	'nsfw', 	'narration', 	'naval', 	'ninja', 	'noir', 	'nonlinear', 	'nudity', 	'offroad', 	'old_school', 	'on_rails_shooter', 	'online_co_op', 	'open_world', 	'otome', 	'parkour', 	'parody_', 	'party_based_rpg', 	'perma_death', 	'philisophical', 	'photo_editing', 	'physics', 	'pinball', 	'pirates', 	'pixel_graphics', 	'platformer', 	'point_&_click', 	'political', 	'politics', 	'pool', 	'post_apocalyptic', 	'procedural_generation', 	'programming', 	'psychedelic', 	'psychological', 	'psychological_horror', 	'puzzle', 	'puzzle_platformer', 	'pve', 	'pvp', 	'quick_time_events', 	'rpg', 	'rpgmaker', 	'rts', 	'racing', 	'real_time_tactics', 	'real_time', 	'real_time_with_pause', 	'realistic', 	'relaxing', 	'remake', 	'replay_value', 	'resource_management', 	'retro', 	'rhythm', 	'robots', 	'rogue_like', 	'rogue_lite', 	'romance', 	'rome', 	'runner', 	'sailing', 	'sandbox', 	'satire', 	'sci_fi', 	'science', 	'score_attack', 	'sequel', 	'sexual_content', 	'shoot_em_up', 	'shooter', 	'short', 	'side_scroller', 	'silent_protagonist', 	'simulation', 	'skateboarding', 	'skating', 	'skiing', 	'sniper', 	'snow', 	'snowboarding', 	'soccer', 	'software', 	'software_training', 	'sokoban', 	'souls_like', 	'soundtrack', 	'space', 	'space_sim', 	'spectacle_fighter', 	'spelling', 	'split_screen', 	'sports', 	'star_wars', 	'stealth', 	'steam_machine', 	'steampunk', 	'story_rich', 	'strategy', 	'strategy_rpg', 	'stylized', 	'submarine', 	'superhero', 	'supernatural', 	'surreal', 	'survival', 	'survival_horror', 	'swordplay', 	'tactical', 	'tactical_rpg', 	'tanks', 	'team_based', 	'tennis', 	'text_based', 	'third_person', 	'third_person_shooter', 	'thriller', 	'time_attack', 	'time_management', 	'time_manipulation', 	'time_travel', 	'top_down', 	'top_down_shooter', 	'touch_friendly', 	'tower_defense', 	'trackir', 	'trading', 	'trading_card_game', 	'trains', 	'transhumanism', 	'turn_based', 	'turn_based_combat', 	'turn_based_strategy', 	'turn_based_tactics', 	'tutorial', 	'twin_stick_shooter', 	'typing', 	'underground', 	'underwater', 	'unforgiving', 	'utilities', 	'vr', 	'vr_only', 	'vampire', 	'video_production', 	'villain_protagonist', 	'violent', 	'visual_novel', 	'voice_control', 	'voxel', 	'walking_simulator', 	'war', 	'wargame', 	'warhammer_40k', 	'web_publishing', 	'werewolves', 	'western', 	'word_game', 	'world_war_i', 	'world_war_ii', 	'wrestling', 	'zombies', 	'e_sports']].values
y = df['bins'].values

X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.4, random_state=42, stratify=y)
X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size=0.5, random_state=42, stratify=y_val)

X_val.shape

"""### Confusion Matrix Code"""

def plot_confusion_matrix(cm,
                          target_names,
                          title='Confusion matrix',
                          cmap=None,
                          normalize=True):
    """
    given a sklearn confusion matrix (cm), make a nice plot

    Arguments
    ---------
    cm:           confusion matrix from sklearn.metrics.confusion_matrix

    target_names: given classification classes such as [0, 1, 2]
                  the class names, for example: ['high', 'medium', 'low']

    title:        the text to display at the top of the matrix

    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm
                  see http://matplotlib.org/examples/color/colormaps_reference.html
                  plt.get_cmap('jet') or plt.cm.Blues

    normalize:    If False, plot the raw numbers
                  If True, plot the proportions

    Usage
    -----
    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by
                                                              # sklearn.metrics.confusion_matrix
                          normalize    = True,                # show proportions
                          target_names = y_labels_vals,       # list of names of the classes
                          title        = best_estimator_name) # title of graph

    Citiation
    ---------
    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html

    """
    import matplotlib.pyplot as plt
    import numpy as np
    import itertools

    accuracy = np.trace(cm) / float(np.sum(cm))
    misclass = 1 - accuracy

    if cmap is None:
        cmap = plt.get_cmap('Blues')

    plt.figure(figsize=(8, 6))
    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()

    if target_names is not None:
        tick_marks = np.arange(len(target_names))
        plt.xticks(tick_marks, target_names, rotation=45)
        plt.yticks(tick_marks, target_names)

    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]


    thresh = cm.max() / 1.5 if normalize else cm.max() / 2
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        if normalize:
            plt.text(j, i, "{:0.4f}".format(cm[i, j]),
                     horizontalalignment="center",
                     color="white" if cm[i, j] > thresh else "black")
        else:
            plt.text(j, i, "{:,}".format(cm[i, j]),
                     horizontalalignment="center",
                     color="white" if cm[i, j] > thresh else "black")


    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))
    plt.show()

"""### 0. Linear Regression"""

reg = LinearRegression()
reg.fit(X_train, y_train)
y_pred = reg.predict(X_train)
y_pred = np.exp(y_pred)

print('Mean Absolute Error:', metrics.mean_absolute_error(np.exp(y_train), y_pred))  
print('Mean Squared Error:', metrics.mean_squared_error(np.exp(y_train), y_pred))  
print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(np.exp(y_train), y_pred)))
print('Variance score: %.2f' % metrics.r2_score(np.exp(y_train), y_pred))

y_pred

np.exp(y_train)

y_pred = reg.predict(X_test)

print('Mean Absolute Error:', metrics.mean_absolute_error(y_val, y_pred))  
print('Mean Squared Error:', metrics.mean_squared_error(y_val, y_pred))  
print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_val, y_pred)))
print('Variance score: %.2f' % metrics.r2_score(y_val, y_pred))

"""### 1. Logistic Regression"""

X_train.shape

y_train.shape

# Log reg

# Fit to training set
model = LogisticRegression(solver='saga', multi_class='multinomial', max_iter=1000)
model.fit(X_train,y_train)

# Predictions on training set
y_pred_train = model.predict(X_train)
metrics.confusion_matrix(y_train, y_pred_train, labels=[0, 1, 2, 3])
# pd.crosstab(y_train, y_pred, rownames=['True'], colnames=['Predicted'], margins=True)

metrics.f1_score(y_train, y_pred_train, average='micro')

y_train_b = label_binarize(y_train, bin_num)
y_pred_train_b = label_binarize(y_pred_train, bin_num)
roc_auc_score(y_train_b, y_pred_train_b)

# Predictions on val set
y_pred_val = model.predict(X_val)
metrics.confusion_matrix(y_val, y_pred_val, labels=[0, 1, 2, 3])

metrics.f1_score(y_val, y_pred_val, average='micro')

y_val_b = label_binarize(y_val, bin_num)
y_pred_val_b = label_binarize(y_pred_val, bin_num)
roc_auc_score(y_val_b, y_pred_val_b)

# Test set
y_pred_test = model.predict(X_test)
metrics.confusion_matrix(y_test, y_pred_test, labels=[0, 1, 2, 3])

metrics.f1_score(y_test, y_pred_test, average='micro')

y_test_b = label_binarize(y_test, bin_num)
y_pred_test_b = label_binarize(y_pred_test, bin_num)
roc_auc_score(y_test_b, y_pred_test_b)

# Plot normalized confusion matrix
plt.figure()
cm = metrics.confusion_matrix(y_test, y_pred_test, labels=[0, 1, 2, 3])
# cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
plot_confusion_matrix(cm, normalize=True, target_names=['0','1','2','3'],
                      title='Normalized confusion matrix')
plt.show()

#array = metrics.confusion_matrix(y_test, y_pred_test, labels=[0, 1, 2, 3])
#df_cm = pd.DataFrame(array, index = [i for i in "0123"],
#                  columns = [i for i in "0123"])
#plt.figure(figsize = (10,7))
#sn.heatmap(df_cm, annot=True)

# Learning Curve

# Learning curve
iter_num = np.linspace(start=1000,stop=2000,num=9)
f1_array_train = np.zeros(10)
f1_array_val = np.zeros(10)

for i in iter_num:
  model = LogisticRegression(solver='saga', multi_class='multinomial', max_iter=i)
  model.fit(X_train,y_train)

  # training set
  y_pred = model.predict(X_train)
  f1_array_train[i] = metrics.f1_score(y_train, y_pred, average='micro') 
  
  # val set
  y_val_pred = model.predict(X_val)
  f1_array_val = metrics.f1_score(y_train, y_val_pred, average='micro')

iter_num = np.linspace(start=1000,stop=2000,num=9)
iter_num

"""### 2. Neural Net"""

# Neural Net
scaler = StandardScaler()
scaler.fit(X_train)
X_train = scaler.transform(X_train)
X_val = scaler.transform(X_val)
mlp = MLPClassifier(hidden_layer_sizes=(50, 50, 50, 50, 50),max_iter=800,alpha=1.2)
mlp.fit(X_train,y_train)

# training set prediction
y_pred_train = mlp.predict(X_train)
metrics.confusion_matrix(y_train, y_pred_train, labels=[0, 1, 2, 3])

metrics.f1_score(y_train, y_pred_train, average='micro')

y_train_b = label_binarize(y_train, bin_num)
y_pred_train_b = label_binarize(y_pred_train, bin_num)
roc_auc_score(y_train_b, y_pred_train_b)

# val set prediction
y_pred_val = mlp.predict(X_val)
metrics.confusion_matrix(y_val, y_pred_val, labels=[0, 1, 2, 3])

metrics.f1_score(y_val, y_pred_val, average='micro')

y_val_b = label_binarize(y_val, bin_num)
y_pred_val_b = label_binarize(y_pred_val, bin_num)
roc_auc_score(y_val_b, y_pred_val_b)

# Test set
y_pred_test = mlp.predict(X_test)
metrics.confusion_matrix(y_test, y_pred_test, labels=[0, 1, 2, 3])

metrics.f1_score(y_test, y_pred_test, average='micro')

y_test_b = label_binarize(y_test, bin_num)
y_pred_test_b = label_binarize(y_pred_test, bin_num)
roc_auc_score(y_test_b, y_pred_test_b)

# Plot normalized confusion matrix
plt.figure()
cm = metrics.confusion_matrix(y_test, y_pred_test, labels=[0, 1, 2, 3])
# cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
plot_confusion_matrix(cm, normalize=True, target_names=['0','1','2','3'],
                      title='Normalized confusion matrix')
plt.show()

# Learning curve
node_num = np.zeros(10)
f1_array_train = np.zeros(10)
f1_array_val = np.zeros(10)

for i in range(0,10):
  j = (i+1)*10
  mlp = MLPClassifier(hidden_layer_sizes=(j, j, j, j),max_iter=1000)
  mlp.fit(X_train,y_train)

  # training set
  y_pred = mlp.predict(X_train)
  f1_array_train[i] = metrics.f1_score(y_train, y_pred, average='micro') 
  
  # val set
  y_val_pred = mlp.predict(X_val)
  f1_array_val[i] = metrics.f1_score(y_val, y_val_pred, average='micro')

plt.plot([10, 20, 30, 40, 50, 60, 70, 80, 90, 100], f1_array_train, label='Training Set')
plt.plot([10, 20, 30, 40, 50, 60, 70, 80, 90, 100], f1_array_val, label='Test Set')
plt.xlabel('Nodes in Neural Network')
plt.ylabel('F1 Score')
plt.title('Learning Curve for Neural Network')
plt.legend()
plt.show()

"""### 3. Decision trees"""

# Decision trees
clf = tree.DecisionTreeClassifier(max_depth = 5)
clf = clf.fit(X_train, y_train)
clf.get_depth()
depth = clf.get_depth()

# training set prediction
y_pred_train = clf.predict(X_train)
metrics.confusion_matrix(y_train, y_pred_train, labels=[0, 1, 2, 3])

metrics.f1_score(y_train, y_pred_train, average='micro')

y_train_b = label_binarize(y_train, bin_num)
y_pred_train_b = label_binarize(y_pred_train, bin_num)
roc_auc_score(y_train_b, y_pred_train_b)

# val set prediction
y_pred_val = clf.predict(X_val)
metrics.confusion_matrix(y_val, y_pred_val, labels=[0, 1, 2, 3])

metrics.f1_score(y_val, y_pred_val, average='micro')

y_val_b = label_binarize(y_val, bin_num)
y_pred_val_b = label_binarize(y_pred_val, bin_num)
roc_auc_score(y_val_b, y_pred_val_b)

# Test set
y_pred_test = clf.predict(X_test)
metrics.confusion_matrix(y_test, y_pred_test, labels=[0, 1, 2, 3])

metrics.f1_score(y_test, y_pred_test, average='micro')

y_test_b = label_binarize(y_test, bin_num)
y_pred_test_b = label_binarize(y_pred_test, bin_num)
roc_auc_score(y_test_b, y_pred_test_b)

# Plot normalized confusion matrix
plt.figure()
cm = metrics.confusion_matrix(y_test, y_pred_test, labels=[0, 1, 2, 3])
# cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
plot_confusion_matrix(cm, normalize=True, target_names=['0','1','2','3'],
                      title='Normalized confusion matrix')
plt.show()

# Learning Curve
depth_array = list(range(depth))
f1_array_train = np.zeros(depth)
f1_array_val = np.zeros(depth)

for i in depth_array:
  clf = tree.DecisionTreeClassifier(max_depth=i+1)
  clf = clf.fit(X_train, y_train)

  # training set
  y_pred = clf.predict(X_train)
  f1_array_train[i] = metrics.f1_score(y_train, y_pred, average='micro') 
  
  # val set
  y_val_pred = clf.predict(X_val)
  f1_array_val[i] = metrics.f1_score(y_val, y_val_pred, average='micro') 

plt.plot(depth_array, f1_array_train, label='Training Set')
plt.plot(depth_array, f1_array_val, label='Test Set')
plt.xlabel('Depth of Tree')
plt.ylabel('F1 Score')
plt.title('Learning Curve for Decision Tree')
plt.legend()
plt.show()

"""### 4. Neural Net with Regression"""

mlp = MLPRegressor(hidden_layer_sizes=(100,100,100,100), max_iter=1000, shuffle=True, random_state=1)
mlp.fit(X_train,y_train)
mlp.score(X_train,y_train)

y_pred = mlp.predict(X_train)
y_pred = np.exp(y_pred)
y_train_true = np.exp(y_train)

y_pred

max_ind = np.argmax(y_train_true)
y_train_true[max_ind] - y_pred[max_ind]

print('Mean Absolute Error:', metrics.mean_absolute_error(y_train, y_pred))  
print('Mean Squared Error:', metrics.mean_squared_error(y_train, y_pred))  
print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_train, y_pred)))

mlp.score(X_val,y_val)

y_pred = mlp.predict(X_vak)
print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))  
print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  
print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))

y_pred

y_val

